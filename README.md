# ðŸ“š Learning Data Engineering

This repository tracks my learning journey in Data Engineering. It includes multiple hands-on projects designed to apply concepts like batch processing, data modeling, orchestration, and streaming in real-world scenarios

## ðŸš€ Projects in this repo:

| #  | Project Name                 | Description                                           |
|----|------------------------------|-------------------------------------------------------|
| 1  | PySpark CSV to Postgres      | Read CSV with PySpark, clean/transform, write to DB  |
| 2  | Airflow ETL Pipeline         | Build and schedule ETL jobs with Apache Airflow      |
| 3  | Data Modeling in PostgreSQL  | Implement star schema and Slowly Changing Dimensions |
| 4  | Real-Time Streaming          | Stream data using Kafka and PySpark                  |

---

## ðŸ’¡ Goal

To learn and apply data engineering skills by building real-world mini-projects using open-source and cloud tools.

## ðŸ§° Tools & Tech

- PySpark
- PostgreSQL
- Apache Airflow
- Apache Kafka
- Docker
- Cloud Platforms (AWS, GCP, Azure)

---

## ðŸ“Œ Notes

- This is a learning-focused repo â€” perfect for beginners exploring the data engineering path.
- Contributions or suggestions are welcome!

